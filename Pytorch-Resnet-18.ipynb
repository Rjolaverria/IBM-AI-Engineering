{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<a href=\"http://cocl.us/pytorch_link_top\">\n    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/Pytochtop.png\" width=\"750\" alt=\"IBM Product \" />\n</a> "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/cc-logo-square.png\" width=\"200\" alt=\"cognitiveclass.ai logo\" />"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h1><h1>Pre-trained-Models with PyTorch </h1>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "In this lab, you will use pre-trained models to classify between the negative and positive samples; you will be provided with the dataset object. The particular pre-trained model will be resnet18; you will have three questions: \n<ul>\n<li>change the output layer</li>\n<li> train the model</li> \n<li>  identify  several  misclassified samples</li> \n </ul>\nYou will take several screenshots of your work and share your notebook. "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h2>Table of Contents</h2>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n\n\n<ul>\n    <li><a href=\"#download_data\"> Download Data</a></li>\n    <li><a href=\"#auxiliary\"> Imports and Auxiliary Functions </a></li>\n    <li><a href=\"#data_class\"> Dataset Class</a></li>\n    <li><a href=\"#Question_1\">Question 1</a></li>\n    <li><a href=\"#Question_2\">Question 2</a></li>\n    <li><a href=\"#Question_3\">Question 3</a></li>\n</ul>\n<p>Estimated Time Needed: <strong>120 min</strong></p>\n </div>\n<hr>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h2 id=\"download_data\">Download Data</h2>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Download the dataset and unzip the files in your data directory, unlike the other labs, all the data will be deleted after you close  the lab, this may take some time:"
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "--2020-07-14 00:34:08--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip\nResolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\nConnecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2598656062 (2.4G) [application/zip]\nSaving to: \u2018Positive_tensors.zip\u2019\n\n100%[====================================>] 2,598,656,062 44.5MB/s   in 60s    \n\n2020-07-14 00:35:09 (41.1 MB/s) - \u2018Positive_tensors.zip\u2019 saved [2598656062/2598656062]\n\n"
                }
            ],
            "source": "!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip "
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": "!unzip -q Positive_tensors.zip "
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "--2020-07-14 00:37:31--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip\nResolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\nConnecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2111408108 (2.0G) [application/zip]\nSaving to: \u2018Negative_tensors.zip\u2019\n\n100%[====================================>] 2,111,408,108 49.2MB/s   in 46s    \n\n2020-07-14 00:38:17 (44.1 MB/s) - \u2018Negative_tensors.zip\u2019 saved [2111408108/2111408108]\n\n"
                }
            ],
            "source": "! wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip\n!unzip -q Negative_tensors.zip"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We will install torchvision:"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Collecting torchvision\n\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7fd5786ac5c0>: Failed to establish a new connection: [Errno -2] Name or service not known',)': /simple/torchvision/\u001b[0m\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/f1/535a407b4a265adf2dd7c2c2458217e37c5fe83ec97234e66c564592a9a0/torchvision-0.6.1-cp36-cp36m-manylinux1_x86_64.whl (6.6MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6.6MB 5.8MB/s eta 0:00:01\n\u001b[?25hCollecting torch==1.5.1 (from torchvision)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/01/457b49d790b6c4b9720e6f9dbbb617692f6ce8afdaadf425c055c41a7416/torch-1.5.1-cp36-cp36m-manylinux1_x86_64.whl (753.2MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 753.2MB 17kB/s s eta 0:00:01     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                    | 273.5MB 51.0MB/s eta 0:00:10\ufffd\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                | 356.0MB 43.7MB/s eta 0:00:10/s eta 0:00:09\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b          | 509.3MB 45.2MB/s eta 0:00:06\ufffd\ufffd\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 692.8MB 54.5MB/s eta 0:00:02\ufffd\ufffd\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 695.0MB 54.5MB/s eta 0:00:02\n\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from torchvision) (5.4.1)\nRequirement already satisfied: numpy in /opt/conda/envs/Python36/lib/python3.6/site-packages (from torchvision) (1.15.4)\nRequirement already satisfied: future in /opt/conda/envs/Python36/lib/python3.6/site-packages (from torch==1.5.1->torchvision) (0.17.1)\nInstalling collected packages: torch, torchvision\nSuccessfully installed torch-1.5.1 torchvision-0.6.1\n"
                }
            ],
            "source": "!pip install torchvision"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h2 id=\"auxiliary\">Imports and Auxiliary Functions</h2>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The following are the libraries we are going to use for this lab. The <code>torch.manual_seed()</code> is for forcing the random function to give the same number every time we try to recompile it."
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "<torch._C.Generator at 0x7fd78803a6b0>"
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# These are the libraries will be used for this lab.\nimport torchvision.models as models\nfrom PIL import Image\nimport pandas\nfrom torchvision import transforms\nimport torch.nn as nn\nimport time\nimport torch \nimport matplotlib.pylab as plt\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nimport h5py\nimport os\nimport glob\ntorch.manual_seed(0)"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": "from matplotlib.pyplot import imshow\nimport matplotlib.pylab as plt\nfrom PIL import Image\nimport pandas as pd\nimport os"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<!--Empty Space for separating topics-->"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h2 id=\"data_class\">Dataset Class</h2>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": " This dataset class is essentially the same dataset you build in the previous section, but to speed things up, we are going to use tensors instead of jpeg images. Therefor for each iteration, you will skip the reshape step, conversion step to tensors and normalization step."
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "done\n"
                }
            ],
            "source": "# Create your own dataset object\n\nclass Dataset(Dataset):\n\n    # Constructor\n    def __init__(self,transform=None,train=True):\n        directory=\"/home/dsxuser/work\"\n        positive=\"Positive_tensors\"\n        negative='Negative_tensors'\n\n        positive_file_path=os.path.join(directory,positive)\n        negative_file_path=os.path.join(directory,negative)\n        positive_files=[os.path.join(positive_file_path,file) for file in os.listdir(positive_file_path) if file.endswith(\".pt\")]\n        negative_files=[os.path.join(negative_file_path,file) for file in os.listdir(negative_file_path) if file.endswith(\".pt\")]\n        number_of_samples=len(positive_files)+len(negative_files)\n        self.all_files=[None]*number_of_samples\n        self.all_files[::2]=positive_files\n        self.all_files[1::2]=negative_files \n        # The transform is goint to be used on image\n        self.transform = transform\n        #torch.LongTensor\n        self.Y=torch.zeros([number_of_samples]).type(torch.LongTensor)\n        self.Y[::2]=1\n        self.Y[1::2]=0\n        \n        if train:\n            self.all_files=self.all_files[0:30000]\n            self.Y=self.Y[0:30000]\n            self.len=len(self.all_files)\n        else:\n            self.all_files=self.all_files[30000:]\n            self.Y=self.Y[30000:]\n            self.len=len(self.all_files)     \n       \n    # Get the length\n    def __len__(self):\n        return self.len\n    \n    # Getter\n    def __getitem__(self, idx):\n               \n        image=torch.load(self.all_files[idx])\n        y=self.Y[idx]\n                  \n        # If there is any transform method, apply it onto the image\n        if self.transform:\n            image = self.transform(image)\n\n        return image, y\n    \nprint(\"done\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We create two dataset objects, one for the training data and one for the validation data."
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "done\n"
                }
            ],
            "source": "train_dataset = Dataset(train=True)\nvalidation_dataset = Dataset(train=False)\nprint(\"done\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h2 id=\"Question_1\">Question 1</h2>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<b>Prepare a pre-trained resnet18 model :</b>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<b>Step 1</b>: Load the pre-trained model <code>resnet18</code> Set the parameter <code>pretrained</code> to true:"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /home/dsxuser/.cache/torch/checkpoints/resnet18-5c106cde.pth\n"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "fadb5a60467d4ec9b1604ff1cb4e2cc8",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": "HBox(children=(IntProgress(value=0, max=46827520), HTML(value='')))"
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\n"
                }
            ],
            "source": "# Step 1: Load the pre-trained model resnet18\n\n# Type your code here\nmodel = models.resnet18(pretrained=True)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<b>Step 2</b>: Set the attribute <code>requires_grad</code> to <code>False</code>. As a result, the parameters will not be affected by training."
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": "# Step 2: Set the parameter cannot be trained for the pre-trained model\n\n\n# Type your code here\nfor param in model.parameters():\n    param.requires_grad = False"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<code>resnet18</code> is used to classify 1000 different objects; as a result, the last layer has 1000 outputs.  The 512 inputs come from the fact that the previously hidden layer has 512 outputs. "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<b>Step 3</b>: Replace the output layer <code>model.fc</code> of the neural network with a <code>nn.Linear</code> object, to classify 2 different classes. For the parameters <code>in_features </code> remember the last hidden layer has 512 neurons."
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": "model.fc = nn.Linear(512,2)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Print out the model in order to show whether you get the correct answer.<br> <b>(Your peer reviewer is going to mark based on what you print here.)</b>"
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=2, bias=True)\n)\n"
                }
            ],
            "source": "print(model)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h2 id=\"Question_2\">Question 2: Train the Model</h2>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "In this question you will train your, model:"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<b>Step 1</b>: Create a cross entropy criterion function "
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": "# Step 1: Create the loss function\n\n# Type your code here\ncriterion = nn.CrossEntropyLoss()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<b>Step 2</b>: Create a training loader and validation loader object, the batch size should have 100 samples each."
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": "train_loader = DataLoader(dataset= train_dataset, batch_size= 100)\nvalidation_loader = DataLoader(dataset= validation_dataset , batch_size= 100)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<b>Step 3</b>: Use the following optimizer to minimize the loss "
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": "optimizer = torch.optim.Adam([parameters for parameters in model.parameters() if parameters.requires_grad],lr=0.001)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<!--Empty Space for separating topics-->"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "**Complete the following code to calculate  the accuracy on the validation data for one epoch; this should take about 45 minutes. Make sure you calculate the accuracy on the validation data.**"
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [],
            "source": "n_epochs=1\nloss_list=[]\naccuracy_list=[]\ncorrect=0\nN_test=len(validation_dataset)\nN_train=len(train_dataset)\nstart_time = time.time()\n#n_epochs\n\nLoss=0\nstart_time = time.time()\nfor epoch in range(n_epochs):\n    for x, y in train_loader:\n\n        model.train() \n        #clear gradient \n        optimizer.zero_grad()\n        #make a prediction \n        yhat = model(x)\n        # calculate loss \n        loss = criterion(yhat,y)\n        # calculate gradients of parameters \n        loss.backward()\n        # update parameters \n        optimizer.step()\n        \n        loss_list.append(loss.data)\n        \n    correct=0\n    for x_test, y_test in validation_loader:\n        # set model to eval \n        model.eval()\n        #make a prediction \n        z = model(x_test)\n        #find max \n        _, yhat = torch.max(z.data,1)\n        \n       \n        #Calculate misclassified  samples in mini-batch \n        #hint +=(yhat==y_test).sum().item()\n        correct += (yhat == y_test).sum().item()\n   \n    accuracy=correct/N_test\n\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<b>Print out the Accuracy and plot the loss stored in the list <code>loss_list</code> for every iteration and take a screen shot.</b>"
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0.9946"
                    },
                    "execution_count": 19,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "accuracy"
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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\n",
                        "text/plain": "<Figure size 432x288 with 1 Axes>"
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": "plt.plot(loss_list)\nplt.xlabel(\"iteration\")\nplt.ylabel(\"loss\")\nplt.show()\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h2 id=\"Question_3\">Question 3:Find the misclassified samples</h2> "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<b>Identify the first four misclassified samples using the validation data:</b>"
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": " Sample 21, Predicted:0, Actual: 1 \n Sample 268, Predicted:1, Actual: 0 \n Sample 375, Predicted:0, Actual: 1 \n Sample 463, Predicted:0, Actual: 1 \n"
                }
            ],
            "source": "loader = DataLoader(dataset= validation_dataset , batch_size= 1)\nmodel.eval()\ncount = 0\nfor i, sample in enumerate(loader):\n    x,y = sample\n    z = model(x)\n    _, yhat = torch.max(z, 1)\n    if yhat != y:\n        print(f\" Sample {i+1}, Predicted:{yhat.item()}, Actual: {str(y.item())} \")\n        count += 1\n    if count >= 4:\n        break  "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/share-notebooks.html\"> CLICK HERE </a> Click here to see how to share your notebook."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h2>About the Authors:</h2> \n\n<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Copyright &copy; 2018 <a href=\"cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu\">cognitiveclass.ai</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/\">MIT License</a>."
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}